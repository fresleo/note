我将为你提供爬虫分析页面所需的三个API接口的完整数据结构设计。

## 📡 爬虫分析 API 接口设计

### 1️⃣ 爬虫趋势数据接口

**接口路径**：`/statistics/crawler/trend/list`

**请求方法**：`GET`

**请求参数**：
```javascript
{
  startDate: 1729987200000,    // 起始时间戳（毫秒）
  endDate: 1730592000000,      // 结束时间戳（毫秒）
  domain: "avmonkey.tv",       // 域名
  periodType: "daily",         // 统计周期: daily/weekly/monthly
  pageNum: 1,                  // 页码
  pageSize: 100                // 每页数量
}
```

**返回数据结构**：
```json
{
  "code": 200,
  "msg": "查询成功",
  "total": 7,
  "rows": [
    {
      "_id": {
        "timestamp": 1729987200,
        "date": "2025-10-20T00:00:00.000+08:00"
      },
      "date": "2025-10-20T00:00:00.000+08:00",
      "periodType": "daily",
      "domain": "avmonkey.tv",
      "crawlerCount": 342,           // 爬虫访问次数
      "uniqueCrawlerCount": 15,      // 唯一爬虫数量
      "createAt": "2025-10-27T14:00:00.168+08:00"
    },
    {
      "_id": {
        "timestamp": 1730073600,
        "date": "2025-10-21T00:00:00.000+08:00"
      },
      "date": "2025-10-21T00:00:00.000+08:00",
      "periodType": "daily",
      "domain": "avmonkey.tv",
      "crawlerCount": 428,
      "uniqueCrawlerCount": 18,
      "createAt": "2025-10-27T14:00:00.168+08:00"
    }
    // ... 更多日期数据
  ]
}
```

---

### 2️⃣ 页面爬取排行接口

**接口路径**：`/statistics/crawler/page/rank`

**请求方法**：`GET`

**请求参数**：
```javascript
{
  startDate: 1729987200000,    // 起始时间戳（毫秒）
  endDate: 1730592000000,      // 结束时间戳（毫秒）
  domain: "avmonkey.tv",       // 域名
  limit: 10,                   // 返回TOP N（默认10）
  pageNum: 1,
  pageSize: 10
}
```

**返回数据结构**：
```json
{
  "code": 200,
  "msg": "查询成功",
  "total": 10,
  "rows": [
    {
      "path": "/index.html",           // 页面路径
      "crawlerCount": 1234,            // 爬虫访问次数
      "crawlerTypes": [                // 访问该页面的爬虫类型统计
        {
          "type": "Googlebot",
          "count": 856
        },
        {
          "type": "Bingbot",
          "count": 245
        },
        {
          "type": "Baiduspider",
          "count": 133
        }
      ],
      "lastCrawlTime": "2025-10-27T14:23:45.000+08:00"  // 最后爬取时间
    },
    {
      "path": "/about.html",
      "crawlerCount": 987,
      "crawlerTypes": [
        {
          "type": "Googlebot",
          "count": 654
        },
        {
          "type": "Bingbot",
          "count": 333
        }
      ],
      "lastCrawlTime": "2025-10-27T14:20:12.000+08:00"
    },
    {
      "path": "/products/list",
      "crawlerCount": 765,
      "crawlerTypes": [
        {
          "type": "Googlebot",
          "count": 432
        },
        {
          "type": "Baiduspider",
          "count": 333
        }
      ],
      "lastCrawlTime": "2025-10-27T14:18:30.000+08:00"
    }
    // ... 更多页面排行
  ]
}
```

---

### 3️⃣ 实时爬虫详情接口

**接口路径**：`/statistics/crawler/realtime/list`

**请求方法**：`GET`

**请求参数**：
```javascript
{
  domain: "avmonkey.tv",       // 域名
  limit: 50                    // 返回最近N条（默认50）
}
```

**返回数据结构**：
```json
{
  "code": 200,
  "msg": "查询成功",
  "total": 50,
  "rows": [
    {
      "_id": "672d8f3a1b2c3d4e5f6a7b8c",
      "timestamp": 1730012595123,                        // 访问时间戳（毫秒）
      "date": "2025-10-27T14:23:15.123+08:00",          // 格式化时间
      "domain": "avmonkey.tv",                          // 域名
      "path": "/index.html",                            // 访问路径
      "ip": "66.249.66.1",                              // 爬虫IP
      "userAgent": "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)",  // User Agent
      "crawlerType": "Googlebot",                       // 爬虫类型
      "referer": null,                                  // 来源（爬虫通常为null）
      "statusCode": 200,                                // HTTP状态码
      "responseTime": 125,                              // 响应时间（毫秒）
      "createAt": "2025-10-27T14:23:15.123+08:00"
    },
    {
      "_id": "672d8f3a1b2c3d4e5f6a7b8d",
      "timestamp": 1730012590456,
      "date": "2025-10-27T14:23:10.456+08:00",
      "domain": "avmonkey.tv",
      "path": "/products/detail/123",
      "ip": "157.55.39.171",
      "userAgent": "Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)",
      "crawlerType": "Bingbot",
      "referer": null,
      "statusCode": 200,
      "responseTime": 89,
      "createAt": "2025-10-27T14:23:10.456+08:00"
    },
    {
      "_id": "672d8f3a1b2c3d4e5f6a7b8e",
      "timestamp": 1730012585789,
      "date": "2025-10-27T14:23:05.789+08:00",
      "domain": "avmonkey.tv",
      "path": "/api/data",
      "ip": "220.181.108.95",
      "userAgent": "Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)",
      "crawlerType": "Baiduspider",
      "referer": null,
      "statusCode": 200,
      "responseTime": 234,
      "createAt": "2025-10-27T14:23:05.789+08:00"
    }
    // ... 更多实时记录（最多50条）
  ]
}
```

---

### 🔧 爬虫类型枚举（crawlerType）

```javascript
const CrawlerTypes = {
  GOOGLEBOT: 'Googlebot',        // Google 搜索引擎
  BINGBOT: 'Bingbot',            // Bing 搜索引擎
  BAIDUSPIDER: 'Baiduspider',    // 百度搜索引擎
  YANDEXBOT: 'YandexBot',        // Yandex 搜索引擎
  SOGOU: 'Sogou',                // 搜狗搜索引擎
  YAHOO: 'Yahoo Slurp',          // Yahoo 搜索引擎
  DUCKDUCKBOT: 'DuckDuckBot',    // DuckDuckGo 搜索引擎
  FACEBOOKBOT: 'facebookexternalhit',  // Facebook 爬虫
  TWITTERBOT: 'Twitterbot',      // Twitter 爬虫
  LINKEDINBOT: 'LinkedInBot',    // LinkedIn 爬虫
  SEMRUSH: 'SemrushBot',         // SEO 工具爬虫
  AHREFSBOT: 'AhrefsBot',        // SEO 工具爬虫
  UNKNOWN: 'Unknown'             // 未识别爬虫
}
```

---

### 📊 字段说明

#### **通用字段**
- `_id`：MongoDB 文档ID或复合键
- `timestamp`：Unix 时间戳（秒或毫秒）
- `date`：ISO 8601 格式的日期时间字符串
- `domain`：域名
- `createAt`：数据创建时间

#### **趋势数据特有字段**
- `crawlerCount`：爬虫访问总次数
- `uniqueCrawlerCount`：唯一爬虫数量（按IP或User Agent去重）
- `periodType`：统计周期（daily/weekly/monthly）

#### **排行数据特有字段**
- `path`：页面路径
- `crawlerTypes`：访问该页面的爬虫类型分布
- `lastCrawlTime`：最后一次被爬取的时间

#### **实时数据特有字段**
- `ip`：爬虫IP地址
- `userAgent`：完整的User Agent字符串
- `crawlerType`：识别出的爬虫类型
- `referer`：HTTP Referer（爬虫通常为null）
- `statusCode`：HTTP响应状态码
- `responseTime`：服务器响应时间（毫秒）

---

### 💡 前端使用示例

```javascript
// 1. 获取爬虫趋势
getCrawlerTrend({ 
  domain: 'avmonkey.tv', 
  startDate: Date.now() - 7*24*60*60*1000, 
  endDate: Date.now(),
  periodType: 'daily'
}).then(res => {
  const dates = res.rows.map(item => formatDate(item.date))
  const counts = res.rows.map(item => item.crawlerCount)
  renderCrawlerTrendChart(dates, counts)
})

// 2. 获取页面排行
getCrawlerPageRank({ 
  domain: 'avmonkey.tv', 
  limit: 10 
}).then(res => {
  const pages = res.rows.map(item => item.path)
  const counts = res.rows.map(item => item.crawlerCount)
  renderCrawlerRankChart(pages, counts)
})

// 3. 获取实时爬虫（每5秒调用）
setInterval(() => {
  getCrawlerRealtime({ domain: 'avmonkey.tv' }).then(res => {
    this.realtimeCrawlerData = res.rows
  })
}, 5000)
```

---

这些数据结构已经完整且规范，可以直接用于前后端开发。需要我帮你创建对应的 API 调用方法吗？
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwMjUzMjU3OV19
-->